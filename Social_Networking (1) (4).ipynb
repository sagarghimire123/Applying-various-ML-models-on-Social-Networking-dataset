{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gT8i2l4NkHve"
      },
      "outputs": [],
      "source": [
        "## project 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WElXPpqfkJSi"
      },
      "source": [
        "### This project is basically about apply various ML models and get the best model out of all applied. The data set is very small with 400 rows which seems like a sampple data. Initially we are applying EDA no feature engineering is required here since there are only 3 columns.\n",
        "\n",
        "### After we are done with EDA we are applying various ML models such as Logistic, Knn,DT and R-forest models. For this process `we are performing grid search and hyper parameter tunning to improve the performance of each models.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJKTrd1GOriV"
      },
      "outputs": [],
      "source": [
        "#3 import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yWmWELr0O2a-"
      },
      "outputs": [],
      "source": [
        "## import dataset\n",
        "df= pd.read_csv(\"Social_Network_Ads.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8B8PICNkYtD"
      },
      "outputs": [],
      "source": [
        "## check the dimension\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNHWeKbORVXD"
      },
      "outputs": [],
      "source": [
        "#3 drop the unwanted columns\n",
        "df.drop(['User ID', \"Gender\"], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLQDWQhRR32K"
      },
      "outputs": [],
      "source": [
        "#3 display the samples\n",
        "df.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jcQFwHads_83"
      },
      "outputs": [],
      "source": [
        "df.Purchased.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCnZcijjtKHY"
      },
      "source": [
        "### The dataset seems to be imbalanced as not purchased data are about double of the purcahsed ones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7DYbYJ6t9iH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_XjvR-uDtJDo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SNs81gjLPTz-"
      },
      "outputs": [],
      "source": [
        "## display the info about dtypea nd null values\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X13o0CiLPVlq"
      },
      "outputs": [],
      "source": [
        "#3 display the statistical values\n",
        "df.describe().T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtK3LY17PcU7"
      },
      "outputs": [],
      "source": [
        "## plot a pairplot to see the correlation between features\n",
        "sns.pairplot(df, hue='Purchased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RqLP5R-WPuDm"
      },
      "outputs": [],
      "source": [
        "## joit plot for correlation\n",
        "sns.jointplot(x='Age',y='EstimatedSalary',data=df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OUxU9cO1Tkib"
      },
      "outputs": [],
      "source": [
        "## start  modeling\n",
        "X= df.drop('Purchased', axis=1)\n",
        "y= df['Purchased']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xy-nSwprUKy7"
      },
      "outputs": [],
      "source": [
        "## import sklearn libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ycwB3DFQuNPN"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Apply SMOTE to balance the training data\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_resampled_scaled = scaler.fit_transform(X_resampled)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-16w5F8VyJFW"
      },
      "outputs": [],
      "source": [
        "resampled_df = pd.concat([pd.DataFrame(X_resampled, columns=X.columns), pd.DataFrame(y_resampled, columns=['Purchased'])], axis=1)\n",
        "resampled_df.Purchased.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2rrtQ6gv47y"
      },
      "outputs": [],
      "source": [
        "# Logistic Regression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define hyperparameters grid for Logistic Regression\n",
        "param_grid = {\n",
        "    'penalty': ['l1', 'l2'],  # Regularization penalty\n",
        "    'C': [0.001, 0.01, 0.1, 1, 10, 100],  # Inverse of regularization strength\n",
        "    'solver': ['liblinear', 'saga'],  # Algorithm to use in the optimization problem\n",
        "    'max_iter': [100, 200, 300],  # Maximum number of iterations for the solvers\n",
        "    'class_weight': ['balanced', None]  # Weights associated with classes\n",
        "}\n",
        "\n",
        "# Initialize Logistic Regression model\n",
        "logistic_model = LogisticRegression()\n",
        "\n",
        "# Perform Grid Search Cross-Validation\n",
        "grid_search = GridSearchCV(estimator=logistic_model, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_resampled_scaled, y_resampled)\n",
        "\n",
        "# Get the best parameters and best score\n",
        "best_params = grid_search.best_params_\n",
        "best_score = grid_search.best_score_\n",
        "\n",
        "# Print the best parameters and best score\n",
        "print(\"Best Parameters:\", best_params)\n",
        "print(\"Best Score:\", best_score)\n",
        "\n",
        "# Use the best parameters to train the Logistic Regression model\n",
        "best_logistic_model = LogisticRegression(**best_params)\n",
        "best_logistic_model.fit(X_resampled_scaled, y_resampled)\n",
        "best_logistic_y_pred = best_logistic_model.predict(X_test_scaled)\n",
        "\n",
        "# Print the classification report for the best Logistic Regression model\n",
        "print(\"Logistic Regression Classification Report (Best Model):\")\n",
        "print(classification_report(y_test, best_logistic_y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ACww1rOLv71A"
      },
      "outputs": [],
      "source": [
        "## 1. Knn\n",
        "knn_param_grid = {\n",
        "    'n_neighbors': [3, 5, 7, 9],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'metric': ['euclidean', 'manhattan']\n",
        "}\n",
        "\n",
        "# Define the KNN model\n",
        "knn_model = KNeighborsClassifier()\n",
        "\n",
        "# Perform GridSearchCV\n",
        "knn_grid_search = GridSearchCV(estimator=knn_model, param_grid=knn_param_grid, cv=5, scoring='accuracy')\n",
        "knn_grid_search.fit(X_resampled_scaled, y_resampled)\n",
        "\n",
        "# Get the best parameters and score\n",
        "knn_best_params = knn_grid_search.best_params_\n",
        "knn_best_score = knn_grid_search.best_score_\n",
        "\n",
        "# Print best parameters and score\n",
        "print(\"KNN Best Parameters:\", knn_best_params)\n",
        "print(\"KNN Best Score:\", knn_best_score)\n",
        "\n",
        "# Create KNN model with best parameters\n",
        "knn_model = KNeighborsClassifier(**knn_best_params)\n",
        "\n",
        "# Fit the model to the resampled data\n",
        "knn_model.fit(X_resampled_scaled, y_resampled)\n",
        "\n",
        "# Make predictions on the test set\n",
        "knn_y_pred = knn_model.predict(X_test_scaled)\n",
        "\n",
        "# Print classification report\n",
        "print(\"KNN Classification Report:\")\n",
        "print(classification_report(y_test, knn_y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LAZvIzn_v99m"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define the Decision Tree parameter grid\n",
        "dt_param_grid = {\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_depth': [None, 5, 10, 15, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Define the Decision Tree model\n",
        "dt_model = DecisionTreeClassifier()\n",
        "\n",
        "# Perform GridSearchCV\n",
        "dt_grid_search = GridSearchCV(estimator=dt_model, param_grid=dt_param_grid, cv=5, scoring='accuracy')\n",
        "dt_grid_search.fit(X_resampled_scaled, y_resampled)\n",
        "\n",
        "# Get the best parameters and score\n",
        "dt_best_params = dt_grid_search.best_params_\n",
        "dt_best_score = dt_grid_search.best_score_\n",
        "\n",
        "# Print best parameters and score\n",
        "print(\"Decision Tree Best Parameters:\", dt_best_params)\n",
        "print(\"Decision Tree Best Score:\", dt_best_score)\n",
        "\n",
        "# Create Decision Tree model with best parameters\n",
        "dt_model = DecisionTreeClassifier(**dt_best_params)\n",
        "\n",
        "# Fit the model to the resampled data\n",
        "dt_model.fit(X_resampled_scaled, y_resampled)\n",
        "\n",
        "# Make predictions on the test set\n",
        "dt_y_pred = dt_model.predict(X_test_scaled)\n",
        "\n",
        "# Print classification report\n",
        "print(\"Decision Tree Classification Report:\")\n",
        "print(classification_report(y_test, dt_y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wX0-2b7Iwclm"
      },
      "outputs": [],
      "source": [
        "# Define the Random Forest parameter grid\n",
        "rf_param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_depth': [None, 5, 10, 15, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'class_weight': ['balanced', 'balanced_subsample']\n",
        "}\n",
        "\n",
        "# Define the Random Forest model\n",
        "rf_model = RandomForestClassifier()\n",
        "\n",
        "# Perform GridSearchCV\n",
        "rf_grid_search = GridSearchCV(estimator=rf_model, param_grid=rf_param_grid, cv=5, scoring='accuracy')\n",
        "rf_grid_search.fit(X_resampled_scaled, y_resampled)\n",
        "\n",
        "# Get the best parameters and score\n",
        "rf_best_params = rf_grid_search.best_params_\n",
        "rf_best_score = rf_grid_search.best_score_\n",
        "\n",
        "# Print best parameters and score\n",
        "print(\"Random Forest Best Parameters:\", rf_best_params)\n",
        "print(\"Random Forest Best Score:\", rf_best_score)\n",
        "\n",
        "# Create Random Forest model with best parameters\n",
        "rf_model = RandomForestClassifier(**rf_best_params)\n",
        "\n",
        "# Fit the model to the resampled data\n",
        "rf_model.fit(X_resampled_scaled, y_resampled)\n",
        "\n",
        "# Make predictions on the test set\n",
        "rf_y_pred = rf_model.predict(X_test_scaled)\n",
        "\n",
        "# Print classification report\n",
        "print(\"Random Forest Classification Report:\")\n",
        "print(classification_report(y_test, rf_y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5QifASPN2tT"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "log_accuracy = accuracy_score(y_test, best_logistic_y_pred)\n",
        "Knn_accuracy = accuracy_score(y_test, knn_y_pred)\n",
        "dtree_accuracy = accuracy_score(y_test, dt_y_pred)\n",
        "rfc_accuracy = accuracy_score(y_test, rf_y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0HMfDa4wyb-"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "log_accuracy = accuracy_score(y_test, logistic_y_pred)\n",
        "Knn_accuracy = accuracy_score(y_test, knn_y_pred)\n",
        "dtree_accuracy = accuracy_score(y_test, dt_y_pred)\n",
        "rfc_accuracy = accuracy_score(y_test, rf_y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DdJ6Mii9oufh"
      },
      "outputs": [],
      "source": [
        "#3 create a df with above values\n",
        "model_names = ['Logistic Regression', 'K-Nearest Neighbors',  'Decision Tree', 'Random Forest']\n",
        "accuracy_scores = [log_accuracy, Knn_accuracy, dtree_accuracy, rfc_accuracy]\n",
        "\n",
        "# Initialize DataFrame\n",
        "accuracy_df = pd.DataFrame({'Model': model_names, 'Accuracy': accuracy_scores})\n",
        "\n",
        "# Highlight the row with the best accuracy score\n",
        "accuracy_df_style = accuracy_df.style.highlight_max(subset=['Accuracy'], color='lightgreen')\n",
        "\n",
        "# Print the DataFrame\n",
        "accuracy_df_style\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjxwS1JPmwP0"
      },
      "source": [
        "### 4. Evaluate the model accuracy and suggest the best model out of all 5 models to be applied in the dataset.\n",
        "### Answer: Among the four models used  the best models seems to be Knn and Random Forest Model with best accuracy of 93% with similar precision and recall values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqbPXSvLoaRc"
      },
      "source": [
        "### ### 5. interpret the classification report for the dataset and explain why the model is best fit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-fFMq-PIOQ5c"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_test, knn_y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SI_Zx1pRpyC4"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_test, rf_y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "welr61WtxjwH"
      },
      "source": [
        "### Both knn and random forest models demonstrate nuanced performance across both classes. For class 0 (not purchased), there is high precision, suggesting that when the model predicts an instance as not purchased, they are  correct about 98% of the time. However, the recall for class 0 is slightly lower, indicating that while the models are accurate in labeling instances as not purchased, they might miss some actual instances of not being purchased. On the other hand, for class 1 (purchased), there is slightly lower precision but notably high recall. This indicates that while the models may occasionally mislabel an instance as purchased, they are effective at capturing most of the actual purchased instances. This quality is particularly valuable in scenarios like targeted marketing or fraud detection, where correctly identifying positive cases is crucial.\n",
        "### Overall, with an accuracy of 93%, both models demonstrate strong predictive capabilities. Also, it's important to acknowledge the trade-offs between precision and recall. The high recall for class 1 suggests the model is adept at identifying purchased instances, but the slightly lower precision means there could be some false positives."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDs2b9fuGIF3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RulKsnEeGIF3"
      },
      "source": [
        "## The part below this line is an extra job which is not a part of project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xbId9VW9V89r"
      },
      "outputs": [],
      "source": [
        "## lets apply pycaret library as apply some more models\n",
        "!pip install pycaret\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNDpm_oCWERL"
      },
      "outputs": [],
      "source": [
        "from pycaret.classification import *\n",
        "s = setup(df, target = 'Purchased', session_id = 123)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g602ZwOoYhHh"
      },
      "outputs": [],
      "source": [
        "best_model = compare_models()\n",
        "tuned_model = tune_model(best_model)\n",
        "evaluate_model(tuned_model)\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
